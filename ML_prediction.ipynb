{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Finland', 'USA', 'Japan', 'Thailand', 'United Kingdom', 'Germany',\n",
    "       'China', 'Hong Kong (SAR) China', 'Sweden', 'Singapore', 'Spain',\n",
    "       'Korea Republic of', 'France', 'Denmark', 'India',\n",
    "       'Russian Federation', 'Italy', 'Norway', 'Greece', 'Netherlands',\n",
    "       'Estonia', 'Poland', 'Switzerland', 'Hungary', 'Austria',\n",
    "       'Czech Republic', 'Portugal']\n",
    "\n",
    "nationalities = ['FI', 'SE', 'DE', 'JP', 'US', 'GB', 'CN', 'RU', 'KR', 'HK', 'NO',\n",
    "       'AU', 'FR', 'EE', 'DK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocesing automotization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, nationalities, countries):\n",
    "#     df['target'] = df['SSR_CODE'] == 'VGML'\n",
    "    df['target'] = ~df['SSR_CODE'].isna()\n",
    "    df = df.drop(columns=['DV_LEG_H_ID','DV_SEGMENT_H_ID', 'TICKET_TYPE','ALDES','DEPSTN', 'AIRCRAFT_REGISTRATION', 'AIRCRAFT_SUBTYPE',  'FLTDATE_LOCAL', 'NATIONALITY', 'SSR_CODE', 'SSR_SEAT_MEAL'])\n",
    "    df['LDEPTIME_LOCAL'] = pd.to_datetime(df['LDEPTIME_LOCAL'])\n",
    "    \n",
    "    df = df[df.GENDER2.isin(['Male', 'Female'])]\n",
    "    df['GENDER2'] = df['GENDER2'] == 'Male'\n",
    "    \n",
    "    df = df[df.POINT_OF_SALE.isin(nationalities) & (df.ARR_COUNTRY.isin(countries))]\n",
    "    df = df.drop(columns=['POINT_OF_SALE'])\n",
    "    \n",
    "    df = df.drop(columns=['ARRSTN'])\n",
    "    \n",
    "    df = df[df.SERVICE_CLASS.isin(['ECONOMY', 'BUSINESS'])]\n",
    "    df['SERVICE_CLASS'] = df['SERVICE_CLASS'] == 'BUSINESS'\n",
    "    \n",
    "    df['FLIGHT_DURATION'] = df['FLIGHT_DURATION'] / 60\n",
    "    \n",
    "    df['ROUTE_TYPE'] = df['ROUTE_TYPE'] == 'LH'\n",
    "    \n",
    "    df['IS_DAYTIME'] = df['LDEPTIME_LOCAL'].apply(lambda x: x.hour >= 6 and x.hour <= 18)\n",
    "    df['SEASON'] = df['LDEPTIME_LOCAL'].apply(lambda x: (x.month % 12) // 3)\n",
    "    \n",
    "    df = df.drop(columns=['FLTNBR', 'LDEPTIME_LOCAL'])\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['ARR_COUNTRY', 'SEASON','TRANSFER_STATUS','BOOKING_CLASS'])\n",
    "    \n",
    "    labels = df[['target']].astype('int32')\n",
    "    df = df.drop(columns=['target'])\n",
    "    \n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('ALL1.csv').sample(100000)\n",
    "train_preprocessed_data, train_labels = preprocess_data(train_data, nationalities, countries)\n",
    "# train_preprocessed_data = train_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "test_preprocessed_data, test_labels = preprocess_data(test_data, nationalities, countries)\n",
    "# test_preprocessed_data = test_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1 training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "model_1 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.fit(train_preprocessed_data.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =  np.squeeze(train_labels.values)\n",
    "threshold = 0.05\n",
    "\n",
    "y_pred = np.array(model_1.predict_proba(train_preprocessed_data.values)[:, 1])\n",
    "y_pred  = y_pred > threshold\n",
    "y_pred = y_pred.astype(int)  \n",
    "\n",
    "print(f\"XGB accuracy on the test set : {round(np.sum(y_pred == y_test) / len(y_pred), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model_1.feature_importances_,\n",
    "                                   index = test_preprocessed_data.columns,\n",
    "                                    columns=['importances']).sort_values('importances', ascending=False)\n",
    "display(feature_importances.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [bool(p) for p in y_pred]\n",
    "train2_preprocessed_data, train2_labels = train_preprocessed_data[index], train_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.fit(train2_preprocessed_data.values, train2_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =  np.squeeze(train2_labels.values)\n",
    "threshold_2 = 0.4\n",
    "\n",
    "y_pred = np.array(model_2.predict_proba(train2_preprocessed_data.values)[:, 1])\n",
    "y_pred  = y_pred > threshold_2\n",
    "y_pred = y_pred.astype(int)  \n",
    "\n",
    "print(f\"XGB accuracy on the test set : {round(np.sum(y_pred == y_test) / len(y_pred), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(model_2.feature_importances_,\n",
    "                                   index = train2_preprocessed_data.columns,\n",
    "                                    columns=['importances']).sort_values('importances', ascending=False)\n",
    "display(feature_importances.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "val_preprocessed_data, val_labels = preprocess_data(val_data, nationalities, countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(model_1.predict_proba(val_preprocessed_data.values)[:, 1])\n",
    "y_pred = y_pred > threshold\n",
    "y_pred = y_pred.astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [bool(p) for p in y_pred]\n",
    "val2_preprocessed_data, val2_labels = val_preprocessed_data[index], val_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = np.array(model_2.predict_proba(val2_preprocessed_data.values)[:, 1])\n",
    "y_pred_2 = y_pred_2 > threshold_2\n",
    "y_pred_2 = y_pred_2.astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = y_pred\n",
    "pred_labels[pred_labels == 1] = y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.squeeze(val_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------\n",
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('ALL1.csv').sample(50000)\n",
    "train_preprocessed_data, train_labels = preprocess_data(train_data, nationalities, countries)\n",
    "train_preprocessed_data = train_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = IsolationForest(contamination = float(np.sum(train_labels) / train_labels.shape[0])).fit(train_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "test_preprocessed_data, test_labels = preprocess_data(test_data, nationalities, countries)\n",
    "test_preprocessed_data = test_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "print ('Confussion matrix:\\n', confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(novelty=True)\n",
    "lof.fit(train_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lof.predict(test_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "print ('Confussion matrix:\\n', confusion_matrix(test_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
