{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = ['Finland', 'USA', 'Japan', 'Thailand', 'United Kingdom', 'Germany',\n",
    "       'China', 'Hong Kong (SAR) China', 'Sweden', 'Singapore', 'Spain',\n",
    "       'Korea Republic of', 'France', 'Denmark', 'India',\n",
    "       'Russian Federation', 'Italy', 'Norway', 'Greece', 'Netherlands',\n",
    "       'Estonia', 'Poland', 'Switzerland', 'Hungary', 'Austria',\n",
    "       'Czech Republic', 'Portugal']\n",
    "\n",
    "nationalities = ['FI', 'SE', 'DE', 'JP', 'US', 'GB', 'CN', 'RU', 'KR', 'HK', 'NO',\n",
    "       'AU', 'FR', 'EE', 'DK']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocesing automotization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, nationalities, countries):\n",
    "#     df['target'] = df['SSR_CODE'] == 'VGML'\n",
    "    df['target'] = ~df['SSR_CODE'].isna()\n",
    "    df = df.drop(columns=['DV_LEG_H_ID','DV_SEGMENT_H_ID', 'TICKET_TYPE','ALDES','DEPSTN', 'AIRCRAFT_REGISTRATION', 'AIRCRAFT_SUBTYPE',  'FLTDATE_LOCAL', 'NATIONALITY', 'SSR_CODE', 'SSR_SEAT_MEAL'])\n",
    "    df['LDEPTIME_LOCAL'] = pd.to_datetime(df['LDEPTIME_LOCAL'])\n",
    "    \n",
    "    df = df[df.GENDER2.isin(['Male', 'Female'])]\n",
    "    df['GENDER2'] = df['GENDER2'] == 'Male'\n",
    "    \n",
    "    df = df[df.POINT_OF_SALE.isin(nationalities) & (df.ARR_COUNTRY.isin(countries))]\n",
    "    df = df.drop(columns=['POINT_OF_SALE'])\n",
    "    \n",
    "    df = df.drop(columns=['ARRSTN'])\n",
    "    \n",
    "    df = df[df.SERVICE_CLASS.isin(['ECONOMY', 'BUSINESS'])]\n",
    "    df['SERVICE_CLASS'] = df['SERVICE_CLASS'] == 'BUSINESS'\n",
    "    \n",
    "    df['FLIGHT_DURATION'] = df['FLIGHT_DURATION'] / 60\n",
    "    \n",
    "    df['ROUTE_TYPE'] = df['ROUTE_TYPE'] == 'LH'\n",
    "    \n",
    "    df['IS_DAYTIME'] = df['LDEPTIME_LOCAL'].apply(lambda x: x.hour >= 6 and x.hour <= 18)\n",
    "    df['SEASON'] = df['LDEPTIME_LOCAL'].apply(lambda x: (x.month % 12) // 3)\n",
    "    \n",
    "    df = df.drop(columns=['FLTNBR', 'LDEPTIME_LOCAL'])\n",
    "    \n",
    "    df = pd.get_dummies(df, columns=['ARR_COUNTRY', 'SEASON','TRANSFER_STATUS','BOOKING_CLASS'])\n",
    "    \n",
    "    labels = df[['target']].astype('int32')\n",
    "    df = df.drop(columns=['target'])\n",
    "    \n",
    "    return df, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AY54025\\Anaconda3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('ALL1.csv').sample(100000)\n",
    "train_preprocessed_data, train_labels = preprocess_data(train_data, nationalities, countries)\n",
    "# train_preprocessed_data = train_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "test_preprocessed_data, test_labels = preprocess_data(test_data, nationalities, countries)\n",
    "# test_preprocessed_data = test_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 1 training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "model_1 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(train_preprocessed_data.values, train_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB accuracy on the test set : 0.9468\n"
     ]
    }
   ],
   "source": [
    "y_test =  np.squeeze(train_labels.values)\n",
    "threshold = 0.05\n",
    "\n",
    "y_pred = np.array(model_1.predict_proba(train_preprocessed_data.values)[:, 1])\n",
    "y_pred  = y_pred > threshold\n",
    "y_pred = y_pred.astype(int)  \n",
    "\n",
    "print(f\"XGB accuracy on the test set : {round(np.sum(y_pred == y_test) / len(y_pred), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9436843425195753\n",
      "F1 score: 0.5287945908137095\n",
      "Recall: 0.9969230769230769\n",
      "Precision: 0.3598286530223703\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97     69499\n",
      "           1       0.36      1.00      0.53      2275\n",
      "\n",
      "    accuracy                           0.94     71774\n",
      "   macro avg       0.68      0.97      0.75     71774\n",
      "weighted avg       0.98      0.94      0.96     71774\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[65464  4035]\n",
      " [    7  2268]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "\n",
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLIGHT_DURATION</th>\n",
       "      <td>0.281487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOOKING_CLASS_A</th>\n",
       "      <td>0.137700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER2</th>\n",
       "      <td>0.054873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEASON_3</th>\n",
       "      <td>0.050707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEASON_2</th>\n",
       "      <td>0.040417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEASON_1</th>\n",
       "      <td>0.040082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEASON_0</th>\n",
       "      <td>0.036106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importances\n",
       "FLIGHT_DURATION     0.281487\n",
       "BOOKING_CLASS_A     0.137700\n",
       "GENDER2             0.054873\n",
       "SEASON_3            0.050707\n",
       "SEASON_2            0.040417\n",
       "SEASON_1            0.040082\n",
       "SEASON_0            0.036106"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(model_1.feature_importances_,\n",
    "                                   index = test_preprocessed_data.columns,\n",
    "                                    columns=['importances']).sort_values('importances', ascending=False)\n",
    "display(feature_importances.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model 2 training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [bool(p) for p in y_pred]\n",
    "train2_preprocessed_data, train2_labels = train_preprocessed_data[index], train_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(train2_preprocessed_data.values, train2_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB accuracy on the test set : 0.772\n"
     ]
    }
   ],
   "source": [
    "y_test =  np.squeeze(train2_labels.values)\n",
    "threshold_2 = 0.4\n",
    "\n",
    "y_pred = np.array(model_2.predict_proba(train2_preprocessed_data.values)[:, 1])\n",
    "y_pred  = y_pred > threshold_2\n",
    "y_pred = y_pred.astype(int)  \n",
    "\n",
    "print(f\"XGB accuracy on the test set : {round(np.sum(y_pred == y_test) / len(y_pred), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.772013326987149\n",
      "F1 score: 0.6701859077346799\n",
      "Recall: 0.6437389770723104\n",
      "Precision: 0.6988989947343226\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.84      0.83      4035\n",
      "           1       0.70      0.64      0.67      2268\n",
      "\n",
      "    accuracy                           0.77      6303\n",
      "   macro avg       0.75      0.74      0.75      6303\n",
      "weighted avg       0.77      0.77      0.77      6303\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[3406  629]\n",
      " [ 808 1460]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FLIGHT_DURATION</th>\n",
       "      <td>0.239309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BOOKING_CLASS_A</th>\n",
       "      <td>0.082696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IS_FPLUS</th>\n",
       "      <td>0.078191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRANSFER_STATUS_has_transferred</th>\n",
       "      <td>0.064150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GENDER2</th>\n",
       "      <td>0.039214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARR_COUNTRY_Italy</th>\n",
       "      <td>0.031460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SERVICE_CLASS</th>\n",
       "      <td>0.029517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 importances\n",
       "FLIGHT_DURATION                     0.239309\n",
       "BOOKING_CLASS_A                     0.082696\n",
       "IS_FPLUS                            0.078191\n",
       "TRANSFER_STATUS_has_transferred     0.064150\n",
       "GENDER2                             0.039214\n",
       "ARR_COUNTRY_Italy                   0.031460\n",
       "SERVICE_CLASS                       0.029517"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importances = pd.DataFrame(model_2.feature_importances_,\n",
    "                                   index = train2_preprocessed_data.columns,\n",
    "                                    columns=['importances']).sort_values('importances', ascending=False)\n",
    "display(feature_importances.head(7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AY54025\\Anaconda3\\envs\\project\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "val_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "val_preprocessed_data, val_labels = preprocess_data(val_data, nationalities, countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array(model_1.predict_proba(val_preprocessed_data.values)[:, 1])\n",
    "y_pred = y_pred > threshold\n",
    "y_pred = y_pred.astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = [bool(p) for p in y_pred]\n",
    "val2_preprocessed_data, val2_labels = val_preprocessed_data[index], val_labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = np.array(model_2.predict_proba(val2_preprocessed_data.values)[:, 1])\n",
    "y_pred_2 = y_pred_2 > threshold_2\n",
    "y_pred_2 = y_pred_2.astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = y_pred\n",
    "pred_labels[pred_labels == 1] = y_pred_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.squeeze(val_labels.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9586159169550174\n",
      "F1 score: 0.3126436781609196\n",
      "Recall: 0.31627906976744186\n",
      "Precision: 0.3090909090909091\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      7010\n",
      "           1       0.31      0.32      0.31       215\n",
      "\n",
      "    accuracy                           0.96      7225\n",
      "   macro avg       0.64      0.65      0.65      7225\n",
      "weighted avg       0.96      0.96      0.96      7225\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[6858  152]\n",
      " [ 147   68]]\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "print ('F1 score:', f1_score(y_test, y_pred))\n",
    "print ('Recall:', recall_score(y_test, y_pred))\n",
    "print ('Precision:', precision_score(y_test, y_pred))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,y_pred))\n",
    "print ('\\n confussion matrix:\\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ------------------------\n",
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('ALL1.csv').sample(50000)\n",
    "train_preprocessed_data, train_labels = preprocess_data(train_data, nationalities, countries)\n",
    "train_preprocessed_data = train_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "clf = IsolationForest(contamination = float(np.sum(train_labels) / train_labels.shape[0])).fit(train_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('ALL1.csv').sample(10000)\n",
    "test_preprocessed_data, test_labels = preprocess_data(test_data, nationalities, countries)\n",
    "test_preprocessed_data = test_preprocessed_data[['FLIGHT_DURATION', 'ROUTE_TYPE', 'IS_FPLUS', 'GENDER2', 'SERVICE_CLASS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(test_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "print ('Confussion matrix:\\n', confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(novelty=True)\n",
    "lof.fit(train_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lof.predict(test_preprocessed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "print ('Confussion matrix:\\n', confusion_matrix(test_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
